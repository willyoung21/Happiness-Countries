{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_clean_2015 = pd.read_csv('../data/clean/2015_clean.csv')\n",
    "df_clean_2016 = pd.read_csv('../data/clean/2016_clean.csv')  \n",
    "df_clean_2017 = pd.read_csv('../data/clean/2017_clean.csv')  \n",
    "df_clean_2018 = pd.read_csv('../data/clean/2018_clean.csv')  \n",
    "df_clean_2019 = pd.read_csv('../data/clean/2019_clean.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos en la columna 'Region' para el año 2017:\n",
      "2\n",
      "                     Country Region\n",
      "32  Taiwan Province of China    NaN\n",
      "70   Hong Kong S.A.R., China    NaN\n",
      "\n",
      "Valores nulos en la columna 'Region' para el año 2018:\n",
      "2\n",
      "              Country Region\n",
      "37  Trinidad & Tobago    NaN\n",
      "57    Northern Cyprus    NaN\n",
      "\n",
      "Valores nulos en la columna 'Region' para el año 2019:\n",
      "4\n",
      "               Country Region\n",
      "38   Trinidad & Tobago    NaN\n",
      "63     Northern Cyprus    NaN\n",
      "83     North Macedonia    NaN\n",
      "119             Gambia    NaN\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame auxiliar con 'Country' y 'Region' de 2015 y 2016, sin duplicados\n",
    "df_region = pd.concat([df_clean_2015[['Country', 'Region']], df_clean_2016[['Country', 'Region']]]).drop_duplicates()\n",
    "\n",
    "# Función para agregar la columna 'Region' después de 'Country'\n",
    "def merge_region_column(df, df_region):\n",
    "    df = df.merge(df_region, on='Country', how='left')\n",
    "    # Reordenar la columna 'Region' para que aparezca justo después de 'Country'\n",
    "    cols = df.columns.tolist()\n",
    "    idx = cols.index('Country') + 1\n",
    "    cols.insert(idx, cols.pop(cols.index('Region')))\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "# Aplicar la función a cada dataset que necesita la columna 'Region'\n",
    "df_clean_2017 = merge_region_column(df_clean_2017, df_region)\n",
    "df_clean_2018 = merge_region_column(df_clean_2018, df_region)\n",
    "df_clean_2019 = merge_region_column(df_clean_2019, df_region)\n",
    "\n",
    "# Comprobación: mostrar el conteo y los valores nulos de cada dataset después del merge\n",
    "for year, df in zip([2017, 2018, 2019], [df_clean_2017, df_clean_2018, df_clean_2019]):\n",
    "    print(f\"\\nValores nulos en la columna 'Region' para el año {year}:\")\n",
    "    print(df['Region'].isnull().sum())\n",
    "    print(df[df['Region'].isnull()][['Country', 'Region']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Países con valores nulos en 'Region':\n",
      " 32    Taiwan Province of China\n",
      "70     Hong Kong S.A.R., China\n",
      "Name: Country, dtype: object\n",
      "\n",
      "Posibles coincidencias en el dataset de 2015:\n",
      "Taiwan Province of China posibles coincidencias en 2015:\n",
      "    Country        Region\n",
      "37  Taiwan  Eastern Asia \n",
      "\n",
      "Hong Kong S.A.R., China posibles coincidencias en 2015:\n",
      "       Country        Region\n",
      "71  Hong Kong  Eastern Asia \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar si los países con valores nulos tienen nombres alternativos en el dataset de 2015\n",
    "missing_regions = df_clean_2017[df_clean_2017['Region'].isnull()]['Country']\n",
    "print(\"\\nPaíses con valores nulos en 'Region':\\n\", missing_regions)\n",
    "\n",
    "print(\"\\nPosibles coincidencias en el dataset de 2015:\")\n",
    "for country in missing_regions:\n",
    "    similar_names = df_clean_2015[df_clean_2015['Country'].str.contains(country.split()[0], case=False, na=False)]\n",
    "    print(f\"{country} posibles coincidencias en 2015:\\n\", similar_names[['Country', 'Region']], \"\\n\")\n",
    "\n",
    "# Configurar pandas para mostrar más filas y columnas si es necesario\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este siguiente codigo es fallido, ya que solo estoy usando la primer palabra como coincidencia y no debe ser asi, esto limita la búsqueda para nombres con términos compuestos, como “Northern Cyprus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Países con valores nulos en 'Region':\n",
      " 37    Trinidad & Tobago\n",
      "57      Northern Cyprus\n",
      "Name: Country, dtype: object\n",
      "\n",
      "Posibles coincidencias en el dataset de 2015:\n",
      "Trinidad & Tobago posibles coincidencias en 2015:\n",
      "                 Country                       Region\n",
      "40  Trinidad and Tobago  Latin America and Caribbean \n",
      "\n",
      "Northern Cyprus posibles coincidencias en 2015:\n",
      " Empty DataFrame\n",
      "Columns: [Country, Region]\n",
      "Index: [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar si los países con valores nulos tienen nombres alternativos en el dataset de 2015\n",
    "missing_regions = df_clean_2018[df_clean_2018['Region'].isnull()]['Country']\n",
    "print(\"\\nPaíses con valores nulos en 'Region':\\n\", missing_regions)\n",
    "\n",
    "print(\"\\nPosibles coincidencias en el dataset de 2015:\")\n",
    "for country in missing_regions:\n",
    "    similar_names = df_clean_2015[df_clean_2015['Country'].str.contains(country.split()[0], case=False, na=False)]\n",
    "    print(f\"{country} posibles coincidencias en 2015:\\n\", similar_names[['Country', 'Region']], \"\\n\")\n",
    "\n",
    "# Configurar pandas para mostrar más filas y columnas si es necesario\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos casos utilizamos \"get_close_matches\" para encontrar coincidencias en los nombres basándose en un umbral (cutoff=0.6), esto lo podemos ajustar en el codigo segun nuestro deseo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Países con valores nulos en 'Region':\n",
      " 37    Trinidad & Tobago\n",
      "57      Northern Cyprus\n",
      "Name: Country, dtype: object\n",
      "\n",
      "Posibles coincidencias en el dataset de 2015:\n",
      "Trinidad & Tobago posibles coincidencias en 2015:\n",
      "                 Country                       Region\n",
      "40  Trinidad and Tobago  Latin America and Caribbean \n",
      "\n",
      "Northern Cyprus posibles coincidencias en 2015:\n",
      "          Country          Region\n",
      "65  North Cyprus  Western Europe \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from difflib import get_close_matches\n",
    "\n",
    "# Función para encontrar coincidencias cercanas\n",
    "def find_similar_country(country_name, df_reference, threshold=0.6):\n",
    "    similar_countries = get_close_matches(country_name, df_reference['Country'], n=1, cutoff=threshold)\n",
    "    if similar_countries:\n",
    "        return df_reference[df_reference['Country'] == similar_countries[0]][['Country', 'Region']]\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['Country', 'Region'])\n",
    "\n",
    "# Ejemplo de aplicación al dataset de 2018\n",
    "missing_regions = df_clean_2018[df_clean_2018['Region'].isnull()]['Country']\n",
    "print(\"\\nPaíses con valores nulos en 'Region':\\n\", missing_regions)\n",
    "\n",
    "print(\"\\nPosibles coincidencias en el dataset de 2015:\")\n",
    "for country in missing_regions:\n",
    "    similar_names = find_similar_country(country, df_clean_2015)\n",
    "    print(f\"{country} posibles coincidencias en 2015:\\n\", similar_names, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Países con valores nulos en 'Region':\n",
      " 38     Trinidad & Tobago\n",
      "63       Northern Cyprus\n",
      "83       North Macedonia\n",
      "119               Gambia\n",
      "Name: Country, dtype: object\n",
      "\n",
      "Posibles coincidencias en el dataset de 2015:\n",
      "Trinidad & Tobago posibles coincidencias en 2015:\n",
      "                 Country                       Region\n",
      "40  Trinidad and Tobago  Latin America and Caribbean \n",
      "\n",
      "Northern Cyprus posibles coincidencias en 2015:\n",
      "          Country          Region\n",
      "65  North Cyprus  Western Europe \n",
      "\n",
      "North Macedonia posibles coincidencias en 2015:\n",
      "       Country                      Region\n",
      "92  Macedonia  Central and Eastern Europe \n",
      "\n",
      "Gambia posibles coincidencias en 2015:\n",
      "    Country              Region\n",
      "84  Zambia  Sub-Saharan Africa \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Función para encontrar coincidencias cercanas\n",
    "def find_similar_country(country_name, df_reference, threshold=0.7):\n",
    "    similar_countries = get_close_matches(country_name, df_reference['Country'], n=1, cutoff=threshold)\n",
    "    if similar_countries:\n",
    "        return df_reference[df_reference['Country'] == similar_countries[0]][['Country', 'Region']]\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['Country', 'Region'])\n",
    "\n",
    "# Ejemplo de aplicación al dataset de 2019\n",
    "missing_regions = df_clean_2019[df_clean_2019['Region'].isnull()]['Country']\n",
    "print(\"\\nPaíses con valores nulos en 'Region':\\n\", missing_regions)\n",
    "\n",
    "print(\"\\nPosibles coincidencias en el dataset de 2015:\")\n",
    "for country in missing_regions:\n",
    "    similar_names = find_similar_country(country, df_clean_2015)\n",
    "    print(f\"{country} posibles coincidencias en 2015:\\n\", similar_names, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para mapear nombres alternativos a una versión estándar\n",
    "country_corrections = {\n",
    "    'Taiwan Province of China': 'Taiwan',\n",
    "    'Hong Kong S.A.R., China': 'Hong Kong',\n",
    "    'Trinidad & Tobago': 'Trinidad and Tobago',\n",
    "    'Northern Cyprus': 'North Cyprus',\n",
    "    'North Macedonia': 'Macedonia',\n",
    "    'Gambia': 'Gambia'  # Se añadirá región de forma manual\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en 'Region' para el año 2017 después de la corrección:\n",
      "0\n",
      "Valores nulos en 'Region' para el año 2018 después de la corrección:\n",
      "0\n",
      "Valores nulos en 'Region' para el año 2019 después de la corrección:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Función para encontrar coincidencias de regiones en el dataset de 2015 y asignarlas\n",
    "def assign_missing_regions(df_target, df_reference):\n",
    "    for idx, row in df_target[df_target['Region'].isnull()].iterrows():\n",
    "        country_name = row['Country']\n",
    "        \n",
    "        # Buscar coincidencia en el dataset de 2015 usando la función de similitud\n",
    "        similar_names = find_similar_country(country_name, df_reference)\n",
    "        \n",
    "        # Si se encuentra una coincidencia, asignar la región\n",
    "        if not similar_names.empty:\n",
    "            df_target.loc[idx, 'Region'] = similar_names.iloc[0]['Region']\n",
    "        else:\n",
    "            print(f\"No se encontró coincidencia para: {country_name}\")\n",
    "\n",
    "# Aplicar la función a los datasets de 2017, 2018 y 2019 usando el dataset de 2015 como referencia\n",
    "for df in [df_clean_2017, df_clean_2018, df_clean_2019]:\n",
    "    assign_missing_regions(df, df_clean_2015)\n",
    "\n",
    "# Asignar manualmente la región para \"Gambia\"\n",
    "for df in [df_clean_2017, df_clean_2018, df_clean_2019]:\n",
    "    df.loc[df['Country'] == 'Gambia', 'Region'] = 'Sub-Saharan Africa'\n",
    "\n",
    "# Estandarizar nombres de países una vez completadas las regiones\n",
    "for df in [df_clean_2017, df_clean_2018, df_clean_2019]:\n",
    "    df['Country'] = df['Country'].replace(country_corrections)\n",
    "\n",
    "# Verificar que no queden valores nulos en 'Region'\n",
    "for year, df in zip([2017, 2018, 2019], [df_clean_2017, df_clean_2018, df_clean_2019]):\n",
    "    print(f\"Valores nulos en 'Region' para el año {year} después de la corrección:\")\n",
    "    print(df['Region'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos guardados exitosamente en la carpeta 'data/clean'\n"
     ]
    }
   ],
   "source": [
    "# Guardar los DataFrames en la carpeta data/clean\n",
    "df_clean_2017.to_csv('../data/clean/2017_clean_with_region.csv', index=False)\n",
    "df_clean_2018.to_csv('../data/clean/2018_clean_with_region.csv', index=False)\n",
    "df_clean_2019.to_csv('../data/clean/2019_clean_with_region.csv', index=False)\n",
    "\n",
    "# Confirmación de guardado\n",
    "print(\"Archivos guardados exitosamente en la carpeta 'data/clean'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset combinado ha sido guardado en 'data/clean/final_happiness_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datasets limpios de cada año\n",
    "df_clean_2015 = pd.read_csv('../data/clean/2015_clean.csv')\n",
    "df_clean_2016 = pd.read_csv('../data/clean/2016_clean.csv') \n",
    "df_clean_2017 = pd.read_csv('../data/clean/2017_clean_with_region.csv')\n",
    "df_clean_2018 = pd.read_csv('../data/clean/2018_clean_with_region.csv')\n",
    "df_clean_2019 = pd.read_csv('../data/clean/2019_clean_with_region.csv')\n",
    "\n",
    "# Concatenar los datasets a lo largo de las filas\n",
    "df_final = pd.concat([df_clean_2015, df_clean_2016, df_clean_2017, df_clean_2018, df_clean_2019], ignore_index=True)\n",
    "\n",
    "# Guardar el dataset final combinado\n",
    "df_final.to_csv('../data/proccesed/final_happiness_data.csv', index=False)\n",
    "print(\"El dataset combinado ha sido guardado en 'data/clean/final_happiness_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar pandas para mostrar más filas y columnas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Mostrar las primeras filas para exploración inicial\n",
    "df_final.head(160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset final tiene 782 filas y 9 columnas.\n"
     ]
    }
   ],
   "source": [
    "# Verificar el número de filas y columnas del dataset final\n",
    "num_filas, num_columnas = df_final.shape\n",
    "print(f\"El dataset final tiene {num_filas} filas y {num_columnas} columnas.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
